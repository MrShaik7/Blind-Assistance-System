# ğŸ‘ï¸ğŸ”Š YOLO Voice Assistant â€“ Real-Time Object Detection with Speech

This project combines **YOLOv3 object detection** with **text-to-speech (TTS)** to describe what the camera sees.
Itâ€™s like giving your webcam a voice â€” turning visual inputs into spoken words in real time.

---

## âœ¨ Features

* ğŸ¥ **Real-time Object Detection** using YOLOv3 + OpenCV
* ğŸ§  **Trained on COCO dataset** (80 common object classes)
* ğŸ—£ï¸ **Voice Feedback** with pyttsx3 â€“ announces detected objects
* ğŸ¯ **Spatial Awareness** â€“ describes objects by position (e.g., â€œtop left personâ€ or â€œmid center chairâ€)
* ğŸ’» **Works with Webcam Feed** out-of-the-box

---

## ğŸ¯ Use Cases

* ğŸ‘“ **Assistive Technology** â†’ Helping visually impaired individuals understand surroundings
* ğŸ  **Smart Home** â†’ Real-time monitoring and object narration
* ğŸ¤– **Robotics** â†’ Enable robots/drones to â€œspeakâ€ what they detect
* ğŸ“ **Learning Projects** â†’ Great for exploring **Computer Vision + Speech Synthesis**

---

## ğŸ› ï¸ Tech Stack

* **YOLOv3** â€“ Pretrained on COCO dataset (object detection)
* **OpenCV (cv2)** â€“ Capturing webcam frames + running YOLO inference
* **pyttsx3** â€“ Offline text-to-speech engine
* **NumPy** â€“ Fast matrix computations

---

## ğŸš€ How It Works

1. Capture frames from the webcam
2. Process frames through YOLOv3 for object detection
3. Identify objects + their positions (left/center/right, top/mid/bottom)
4. Convert detections into spoken descriptions using pyttsx3

---

ğŸ‘‰ Do you want me to also suggest a **catchy repo name** for this (something beyond â€œYOLO + speechâ€), like what we did for the PDF/Web RAG projects?
